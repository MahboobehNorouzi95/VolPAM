{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-y2Es7fe0Ohe",
    "outputId": "28b79bd8-f9d3-49ab-a627-d279f0062793"
   },
   "outputs": [],
   "source": [
    "# check GPU availability\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nn61Y0laG71O",
    "outputId": "92f521f1-5e60-4342-c17b-7b1a894fd313"
   },
   "outputs": [],
   "source": [
    "t = TicToc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainVol = np.load('Your Path Here/normalizeddata.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = torch.from_numpy(data).float()\n",
    "\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        #x = process_scan(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "trainData = MyDataset(mainVol)\n",
    "train_loader = DataLoader(trainData,batch_size=10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "\n",
    "class UnFlatten(nn.Module):\n",
    "    def forward(self, input, size=131072):\n",
    "        return input.view(input.size(0), 64, 16, 16, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicConv(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size, stride=1, padding=0, dilation=1, groups=1, relu=True,\n",
    "                 bn=True, bias=False):\n",
    "        super(BasicConv, self).__init__()\n",
    "        self.out_channels = out_planes\n",
    "        self.conv = nn.Conv3d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias)\n",
    "\n",
    "        self.bn = nn.BatchNorm3d(out_planes, eps=1e-5, momentum=0.01, affine=True) if bn else None\n",
    "        self.relu = nn.ReLU() if relu else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        # print('conv block output',x.shape)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Autoencoders(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoders, self).__init__()\n",
    "\n",
    "        self.relu = nn.ReLU(True)\n",
    "\n",
    "        ##encoder layers\n",
    "        self.conv_block_1 = BasicConv(1, 16, 3, stride=1, padding=1, bn=True, relu=True)\n",
    "        self.conv_block_2 = BasicConv(16, 32, 3, stride=1, padding=1, bn=True, relu=True)\n",
    "        self.conv_block_3 = BasicConv(32, 64, 3, stride=1, padding=1, bn=True, relu=True)\n",
    "        self.max_pool = nn.MaxPool3d(2)\n",
    "        self.flatten = Flatten()\n",
    "        self.enclinear = nn.Linear(131072, 1024)\n",
    "        ##decoder layers\n",
    "        self.dec_convtrans_1 = nn.ConvTranspose3d(64, 32, 2, stride=2)\n",
    "        self.dec_convtrans_2 = nn.ConvTranspose3d(32, 16, 2, stride=2)\n",
    "        self.dec_convtrans_3 = nn.ConvTranspose3d(16, 1, 2, stride=2)\n",
    "        self.deconv_batch_norm_1 = nn.BatchNorm3d(32)\n",
    "        self.deconv_batch_norm_2 = nn.BatchNorm3d(16)\n",
    "        self.unflatten = UnFlatten()\n",
    "        self.declinear = nn.Linear(1024, 131072)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        code1 = self.conv_block_1(x)\n",
    "        # print(\"code1:\", code1.shape)\n",
    "        code1 = self.max_pool(code1)\n",
    "        # print(\"code1:\", code1.shape)\n",
    "        code2 = self.conv_block_2(code1)\n",
    "        # print(\"code2:\", code2.shape)\n",
    "        code2 = self.max_pool(code2)\n",
    "        # print(\"code2:\", code2.shape)\n",
    "        code3 = self.conv_block_3(code2)\n",
    "        # print(\"code3:\", code3.shape)\n",
    "        code3 = self.max_pool(code3)\n",
    "        #print(\"code3:\", code3.shape)\n",
    "        code3 = self.flatten(code3)\n",
    "        # print(\"code3:\", code3.shape)\n",
    "        code3 = self.enclinear(code3)\n",
    "        # print(\"code3:\", code3.shape)\n",
    "\n",
    "        # Decoder\n",
    "        out1 = self.declinear(code3)\n",
    "        out1 = self.unflatten(out1)\n",
    "        out1 = self.dec_convtrans_1(out1)\n",
    "        # print(\"out1:\", out1.shape)\n",
    "        out1 = self.deconv_batch_norm_1(out1)\n",
    "        # print(\"out1:\", out1.shape)\n",
    "        out2 = self.dec_convtrans_2(out1)\n",
    "        # print(\"out2:\", out2.shape)\n",
    "        out2 = self.deconv_batch_norm_2(out2)\n",
    "        # print(\"out2:\", out2.shape)\n",
    "        out3 = self.dec_convtrans_3(out2)\n",
    "        # print(\"out3:\", out3.shape)\n",
    "\n",
    "        return code3, out3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoders()\n",
    "model = model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('/home/norouzi1/Thesis_FinalResults/Covid/SavedModels/Autoencoder.pth')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_output = np.loadtxt('/home/norouzi1/Thesis_FinalResults/Covid/SavedModels/enc10.txt')\n",
    "enc_output = enc_output.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.loadtxt('/home/norouzi1/Thesis_FinalResults/Covid/SavedModels/labels.txt')\n",
    "labels = labels.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t7ViV7ZaO-5o"
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = torch.from_numpy(data).float()\n",
    "        self.labels = labels.long()\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.labels[index]\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "labels = torch.from_numpy(labels)\n",
    "trainData = MyDataset(mainVol, labels)\n",
    "train_loader = DataLoader(trainData,batch_size=10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "    \n",
    "class ClassificationModel(nn.Module):   \n",
    "    def __init__(self):\n",
    "        super(ClassificationModel, self).__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            # Defining a 3D convolution layer\n",
    "            nn.Conv3d(1,64,3, stride=1, padding=1),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d((2,2,2)),\n",
    "            # Defining another 3D convolution layer\n",
    "            nn.Conv3d(64,32,3, stride=1, padding=1),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d((2,2,2)),\n",
    "            # Defining another 3D convolution layer\n",
    "            nn.Conv3d(32,16,3, stride=1, padding=1),\n",
    "            nn.BatchNorm3d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d((2,2,2))\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            Flatten(),\n",
    "            nn.Linear(32768, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            #nn.Dropout3d(p=0.5),\n",
    "            nn.Linear(256, 3)\n",
    "        )\n",
    "\n",
    "    # Defining the forward pass    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ClassificationModel()\n",
    "model = model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('Your Path Here/Classifier.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradCAMModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GradCAMModel, self).__init__()\n",
    "        \n",
    "        # get the classification network\n",
    "        self.gradcam = model\n",
    "        \n",
    "        # disect the network to access its last convolutional layer\n",
    "        self.features_conv = self.gradcam.features[:11]\n",
    "        \n",
    "        # get the max pool of the features stem\n",
    "        self.max_pool = nn.MaxPool3d((2,2,2))\n",
    "        \n",
    "        # get the classifier of the model\n",
    "        self.classifier = self.gradcam.classifier\n",
    "        \n",
    "        # placeholder for the gradients\n",
    "        self.gradients = None\n",
    "    \n",
    "    # hook for the gradients of the activations\n",
    "    def activations_hook(self, grad):\n",
    "        self.gradients = grad\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features_conv(x)\n",
    "        \n",
    "        # register the hook\n",
    "        h = x.register_hook(self.activations_hook)\n",
    "        \n",
    "        # apply the remaining pooling\n",
    "        x = self.max_pool(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "    # method for the gradient extraction\n",
    "    def get_activations_gradient(self):\n",
    "        return self.gradients\n",
    "    \n",
    "    # method for the activation exctraction\n",
    "    def get_activations(self, x):\n",
    "        return self.features_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = GradCAMModel()\n",
    "model2 = model2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = torch.load('Your Path Here/GradCAM.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_heat(img):\n",
    "    \"\"\"Resize across z-axis\"\"\"\n",
    "    # Set the desired depth\n",
    "    desired_depth = 64\n",
    "    desired_width = 128\n",
    "    desired_height = 128\n",
    "    # Get current depth\n",
    "    current_depth = img.shape[-1]\n",
    "    current_width = img.shape[0]\n",
    "    current_height = img.shape[1]\n",
    "    # Compute depth factor\n",
    "    depth = current_depth / desired_depth\n",
    "    width = current_width / desired_width\n",
    "    height = current_height / desired_height\n",
    "    depth_factor = 1 / depth\n",
    "    width_factor = 1 / width\n",
    "    height_factor = 1 / height\n",
    "    # Resize across z-axis\n",
    "    img = ndimage.zoom(img, (width_factor, height_factor, depth_factor), order=1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = torch.from_numpy(data).float()\n",
    "        self.labels = labels.long()\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.labels[index]\n",
    "        \n",
    "        return index, x\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "trainData = MyDataset(mainVol, labels)\n",
    "train_loader = DataLoader(trainData,batch_size=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_matrix( X_trn, X_tst):\n",
    "  yTy = np.sum( np.square( X_trn) , axis=1)\n",
    "  xTy = np.dot(X_trn, np.transpose(X_tst))\n",
    "  yTy = yTy.reshape(yTy.size, 1)\n",
    "  dist_matrix = yTy - 2*xTy\n",
    "  return dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sum_mems_0 = []\n",
    "imgs_cl0 = []\n",
    "indx_0 = []\n",
    "num_mems_0 = 0\n",
    "for index, data in train_loader:\n",
    "    if labels[index] == 0:\n",
    "        num_mems_0 += 1\n",
    "        indx_0.append(index)\n",
    "        data = data.unsqueeze(1)\n",
    "        # get the image from the dataloader\n",
    "        main_img = data[0,...]\n",
    "        main_img = main_img.cuda().detach().cpu().numpy()\n",
    "        imgs_cl0.append(main_img)  \n",
    "        img = data.to(device=device, dtype=torch.float) \n",
    "        winning_idx = model2(img).argmax(dim=1)\n",
    "        pred = model2(img)\n",
    "        # get the gradient of the output with respect to the parameters of the model\n",
    "        pred[:,winning_idx].backward()\n",
    "        # pull the gradients out of the model\n",
    "        gradients = model2.get_activations_gradient()\n",
    "        #print(gradients.shape)\n",
    "        # pool the gradients across the channels\n",
    "        alpha_ks = torch.mean(gradients, dim=[0, 2, 3, 4])\n",
    "        #print(pooled_gradients.shape)\n",
    "        # get the activations of the last convolutional layer\n",
    "        weighted_combination = model2.get_activations(img).detach()\n",
    "        #print(activations.shape)\n",
    "        # weight the channels by corresponding gradients\n",
    "        for i in range(16):\n",
    "            weighted_combination[:, i, :, :, :] *= alpha_ks[i]\n",
    "\n",
    "        # average the channels of the activations\n",
    "        heatmap = torch.sum(weighted_combination, dim=1).squeeze()\n",
    "        heatmap = heatmap.detach().cpu().numpy()\n",
    "        heatmap = np.maximum(heatmap, 0)\n",
    "        probability = pred[:,winning_idx].cuda().detach().cpu().numpy()\n",
    "        heatmap *= probability\n",
    "        heatmap = torch.from_numpy(heatmap)\n",
    "        heatmap = heatmap.cuda().detach().cpu()\n",
    "        heatmap_resized = resize_heat(heatmap)\n",
    "        sum_mems_0.append(heatmap_resized)       \n",
    "\n",
    "sum_mems_0 = np.stack(sum_mems_0)\n",
    "sum_mems_0 /= num_mems_0\n",
    "imgs_cl0 = np.stack(imgs_cl0)\n",
    "indx_0 = np.stack(indx_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_means = np.mean(imgs_cl0, 0)\n",
    "print(img_means.shape)\n",
    "resh_vol = np.reshape( imgs_cl0, [imgs_cl0.shape[0],-1])\n",
    "print(resh_vol.shape)\n",
    "resh_mean = np.reshape( img_means, [1,-1])\n",
    "print(resh_mean.shape)\n",
    "dist_matrix = get_distance_matrix(resh_vol, resh_mean)\n",
    "print(dist_matrix.shape)\n",
    "\n",
    "# initialize K\n",
    "K = 10\n",
    "  \n",
    "# Smallest K elements indices\n",
    "# using sorted() + lambda + list slicing\n",
    "res = sorted(range(len(dist_matrix)), key = lambda sub: dist_matrix[sub])[:K]\n",
    "\n",
    "closest_to_mean_0 = [indx_0[i] for i in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "along_datapoints_0 = np.mean(sum_mems_0, axis=0)\n",
    "print(along_datapoints_0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argwhere(np.isnan(sum_mems_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_img_avg_cl0 = np.mean(imgs_cl0, axis=0)\n",
    "main_img_avg_cl0 = main_img_avg_cl0[0,:,:,:]\n",
    "superimposed_img_0 = along_datapoints_0 + main_img_avg_cl0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "along_z = np.mean(along_datapoints_0, axis=2)\n",
    "plt.rcParams['lines.linewidth'] = 30\n",
    "fig = plt.figure(figsize=(100, 60))\n",
    "fig.patch.set_facecolor('slateblue')\n",
    "plt.imshow(along_z)\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis='x', labelsize=200, colors = 'white')\n",
    "ax.tick_params(axis='y', labelsize=200, colors = 'white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "along_xy = along_datapoints_0.mean(axis=(0, 1))\n",
    "plt.rcParams['lines.linewidth'] = 30\n",
    "fig = plt.figure(figsize=(100, 60))\n",
    "fig.patch.set_facecolor('slateblue')\n",
    "plt.xlabel(\"Slice Depth\", fontsize=250, color = 'white')\n",
    "plt.ylabel(\"VolPAM_1D\", fontsize=250, color = 'white')\n",
    "plt.plot(along_xy, color = \"mediumvioletred\") # plotting by columns\n",
    "ax = plt.gca()\n",
    "ax.set_facecolor('midnightblue')\n",
    "ax.tick_params(axis='x', labelsize=200, colors = 'white')\n",
    "ax.tick_params(axis='y', labelsize=200, colors = 'white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_mems_1 = []\n",
    "imgs_cl1 = []\n",
    "indx_1 = []\n",
    "num_mems_1 = 0\n",
    "for index, data in train_loader:\n",
    "    if labels[index] == 1:\n",
    "        num_mems_1 += 1\n",
    "        indx_1.append(index)\n",
    "        data = data.unsqueeze(1)\n",
    "        # get the image from the dataloader\n",
    "        main_img = data[0,...]\n",
    "        main_img = main_img.cuda().detach().cpu().numpy()\n",
    "        imgs_cl1.append(main_img)  \n",
    "        img = data.to(device=device, dtype=torch.float) \n",
    "        winning_idx = model2(img).argmax(dim=1)\n",
    "        pred = model2(img)\n",
    "\n",
    "        # get the gradient of the output with respect to the parameters of the model\n",
    "        pred[:,winning_idx].backward()\n",
    "\n",
    "        # pull the gradients out of the model\n",
    "        gradients = model2.get_activations_gradient()\n",
    "        #print(gradients.shape)\n",
    "        # pool the gradients across the channels\n",
    "        alpha_ks = torch.mean(gradients, dim=[0, 2, 3, 4])\n",
    "        #print(pooled_gradients.shape)\n",
    "        # get the activations of the last convolutional layer\n",
    "        weighted_combination = model2.get_activations(img).detach()\n",
    "        #print(activations.shape)\n",
    "        # weight the channels by corresponding gradients\n",
    "        for i in range(16):\n",
    "            weighted_combination[:, i, :, :, :] *= alpha_ks[i]\n",
    "\n",
    "        # average the channels of the activations\n",
    "        heatmap = torch.sum(weighted_combination, dim=1).squeeze()\n",
    "        heatmap = heatmap.detach().cpu().numpy()\n",
    "        heatmap = np.maximum(heatmap, 0)\n",
    "        probability = pred[:,winning_idx].cuda().detach().cpu().numpy()\n",
    "        heatmap *= probability\n",
    "        heatmap = torch.from_numpy(heatmap)\n",
    "        heatmap = heatmap.cuda().detach().cpu()\n",
    "        heatmap_resized = resize_heat(heatmap)\n",
    "        sum_mems_1.append(heatmap_resized)       \n",
    "        \n",
    "sum_mems_1 = np.stack(sum_mems_1)\n",
    "sum_mems_1 /= num_mems_1\n",
    "imgs_cl1 = np.stack(imgs_cl1)\n",
    "indx_1 = np.stack(indx_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_means = np.mean(imgs_cl1, 0)\n",
    "print(img_means.shape)\n",
    "resh_vol = np.reshape( imgs_cl1, [imgs_cl1.shape[0],-1])\n",
    "print(resh_vol.shape)\n",
    "resh_mean = np.reshape( img_means, [1,-1])\n",
    "print(resh_mean.shape)\n",
    "dist_matrix = get_distance_matrix(resh_vol, resh_mean)\n",
    "print(dist_matrix.shape)\n",
    "\n",
    "# initialize K\n",
    "K = 10\n",
    "  \n",
    "# Smallest K elements indices\n",
    "# using sorted() + lambda + list slicing\n",
    "res = sorted(range(len(dist_matrix)), key = lambda sub: dist_matrix[sub])[:K]\n",
    "\n",
    "closest_to_mean_1 = [indx_1[i] for i in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "along_datapoints_1 = np.mean(sum_mems_1, axis=0)\n",
    "print(along_datapoints_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_img_avg_cl1 = np.mean(imgs_cl1, axis=0)\n",
    "main_img_avg_cl1 = main_img_avg_cl1[0,:,:,:]\n",
    "superimposed_img_1 = along_datapoints_1 + main_img_avg_cl1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "along_z = np.mean(along_datapoints_1, axis=2)\n",
    "plt.rcParams['lines.linewidth'] = 30\n",
    "fig = plt.figure(figsize=(100, 60))\n",
    "fig.patch.set_facecolor('slateblue')\n",
    "plt.imshow(along_z)\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis='x', labelsize=200, colors = 'white')\n",
    "ax.tick_params(axis='y', labelsize=200, colors = 'white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "along_xy = along_datapoints_1.mean(axis=(0, 1))\n",
    "plt.rcParams['lines.linewidth'] = 30\n",
    "fig = plt.figure(figsize=(100, 60))\n",
    "fig.patch.set_facecolor('slateblue')\n",
    "plt.xlabel(\"Slice Depth\", fontsize=250, color = 'white')\n",
    "plt.ylabel(\"VolPAM_1D\", fontsize=250, color = 'white')\n",
    "plt.plot(along_xy, color = \"mediumvioletred\") # plotting by columns\n",
    "ax = plt.gca()\n",
    "ax.set_facecolor('midnightblue')\n",
    "ax.tick_params(axis='x', labelsize=200, colors = 'white')\n",
    "ax.tick_params(axis='y', labelsize=200, colors = 'white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_mems_2 = []\n",
    "imgs_cl2 = []\n",
    "indx_2 = []\n",
    "num_mems_2 = 0\n",
    "for index, data in train_loader:\n",
    "    if labels[index] == 2:\n",
    "        indx_2.append(index) \n",
    "        num_mems_2 += 1\n",
    "        data = data.unsqueeze(1)\n",
    "        # get the image from the dataloader\n",
    "        main_img = data[0,...]\n",
    "        main_img = main_img.cuda().detach().cpu().numpy()\n",
    "        imgs_cl2.append(main_img)  \n",
    "        img = data.to(device=device, dtype=torch.float) \n",
    "        winning_idx = model2(img).argmax(dim=1)\n",
    "        pred = model2(img)\n",
    "\n",
    "        # get the gradient of the output with respect to the parameters of the model\n",
    "        pred[:,winning_idx].backward()\n",
    "\n",
    "        # pull the gradients out of the model\n",
    "        gradients = model2.get_activations_gradient()\n",
    "        #print(gradients.shape)\n",
    "        # pool the gradients across the channels\n",
    "        alpha_ks = torch.mean(gradients, dim=[0, 2, 3, 4])\n",
    "        #print(pooled_gradients.shape)\n",
    "        # get the activations of the last convolutional layer\n",
    "        weighted_combination = model2.get_activations(img).detach()\n",
    "        #print(activations.shape)\n",
    "        # weight the channels by corresponding gradients\n",
    "        for i in range(16):\n",
    "            weighted_combination[:, i, :, :, :] *= alpha_ks[i]\n",
    "\n",
    "        # average the channels of the activations\n",
    "        heatmap = torch.sum(weighted_combination, dim=1).squeeze()\n",
    "        heatmap = heatmap.detach().cpu().numpy()\n",
    "        heatmap = np.maximum(heatmap, 0)\n",
    "        probability = pred[:,winning_idx].cuda().detach().cpu().numpy()\n",
    "        heatmap *= probability\n",
    "        heatmap = torch.from_numpy(heatmap)\n",
    "        heatmap = heatmap.cuda().detach().cpu()\n",
    "        heatmap_resized = resize_heat(heatmap)\n",
    "        sum_mems_2.append(heatmap_resized)       \n",
    "        \n",
    "sum_mems_2 = np.stack(sum_mems_2)\n",
    "sum_mems_2 /= num_mems_2\n",
    "imgs_cl2 = np.stack(imgs_cl2)\n",
    "indx_2 = np.stack(indx_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_means = np.mean(imgs_cl2, 0)\n",
    "print(img_means.shape)\n",
    "resh_vol = np.reshape( imgs_cl2, [imgs_cl2.shape[0],-1])\n",
    "print(resh_vol.shape)\n",
    "resh_mean = np.reshape( img_means, [1,-1])\n",
    "print(resh_mean.shape)\n",
    "dist_matrix = get_distance_matrix(resh_vol, resh_mean)\n",
    "print(dist_matrix.shape)\n",
    "\n",
    "# initialize K\n",
    "K = 10\n",
    "  \n",
    "# Smallest K elements indices\n",
    "# using sorted() + lambda + list slicing\n",
    "res = sorted(range(len(dist_matrix)), key = lambda sub: dist_matrix[sub])[:K]\n",
    "\n",
    "closest_to_mean_2 = [indx_2[i] for i in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "along_datapoints_2 = np.mean(sum_mems_2, axis=0)\n",
    "print(along_datapoints_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_img_avg_cl2 = np.mean(imgs_cl2, axis=0)\n",
    "main_img_avg_cl2 = main_img_avg_cl2[0,:,:,:]\n",
    "superimposed_img_2 = along_datapoints_2 + main_img_avg_cl2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "along_z = np.mean(along_datapoints_2, axis=2)\n",
    "plt.rcParams['lines.linewidth'] = 30\n",
    "fig = plt.figure(figsize=(100, 60))\n",
    "fig.patch.set_facecolor('slateblue')\n",
    "plt.imshow(along_z)\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis='x', labelsize=200, colors = 'white')\n",
    "ax.tick_params(axis='y', labelsize=200, colors = 'white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "along_xy = along_datapoints_2.mean(axis=(0, 1))\n",
    "plt.rcParams['lines.linewidth'] = 30\n",
    "fig = plt.figure(figsize=(100, 60))\n",
    "fig.patch.set_facecolor('slateblue')\n",
    "plt.xlabel(\"Slice Depth\", fontsize=250, color = 'white')\n",
    "plt.ylabel(\"VolPAM_1D\", fontsize=250, color = 'white')\n",
    "plt.plot(along_xy, color = \"mediumvioletred\") # plotting by columns\n",
    "ax = plt.gca()\n",
    "ax.set_facecolor('midnightblue')\n",
    "ax.tick_params(axis='x', labelsize=200, colors = 'white')\n",
    "ax.tick_params(axis='y', labelsize=200, colors = 'white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close0 = [mainVol[i] for i in closest_to_mean_0]\n",
    "close1 = [mainVol[i] for i in closest_to_mean_1]\n",
    "close2 = [mainVol[i] for i in closest_to_mean_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_slices(num_rows, num_columns, width, height, data):\n",
    "    \"\"\"Plot a montage of 20 CT slices\"\"\"\n",
    "    data = np.rot90(np.array(data))\n",
    "    data = np.transpose(data)\n",
    "    data = np.reshape(data, (num_rows, num_columns, width, height))\n",
    "    rows_data, columns_data = data.shape[0], data.shape[1]\n",
    "    heights = [slc[0].shape[0] for slc in data]\n",
    "    widths = [slc.shape[1] for slc in data[0]]\n",
    "    fig_width = 12.0\n",
    "    fig_height = fig_width * sum(heights) / sum(widths)\n",
    "    f, axarr = plt.subplots(\n",
    "        rows_data,\n",
    "        columns_data,\n",
    "        figsize=(fig_width, fig_height),\n",
    "        gridspec_kw={\"height_ratios\": heights},\n",
    "    )\n",
    "    for i in range(rows_data):\n",
    "        for j in range(columns_data):\n",
    "            axarr[i, j].imshow(data[i][j], cmap=\"gray\")\n",
    "            axarr[i, j].axis(\"off\")\n",
    "    plt.subplots_adjust(wspace=0, hspace=0, left=0, right=1, bottom=0, top=1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(np.shape(close0)[0]):\n",
    "    plot_slices(4, 16, 128, 128, np.array(close0)[i,:,:,:])\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(np.shape(close1)[0]):\n",
    "    plot_slices(4, 16, 128, 128, np.array(close1)[i,:,:,:])\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(np.shape(close2)[0]):\n",
    "    plot_slices(4, 16, 128, 128, np.array(close2)[i,:,:,:])\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect arrays in dictionary\n",
    "savedict = {\n",
    "    'A' : superimposed_img_0,\n",
    "    'B' : superimposed_img_1,\n",
    "    'C' : superimposed_img_2\n",
    "}\n",
    "\n",
    "savemat(\"Your Path Here/3DVis_IRANData.mat\", savedict)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CBAM_Ver2_NormRevised.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
