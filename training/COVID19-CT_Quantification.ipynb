{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kcq04LKyzwWY"
   },
   "outputs": [],
   "source": [
    "############ Imports ############\n",
    "%matplotlib inline\n",
    "!pip install nibabel\n",
    "!pip install pytictoc\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import numpy.random as rng\n",
    "import os\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import re\n",
    "import scipy.cluster.hierarchy as shc\n",
    "import scipy.misc\n",
    "import scipy.ndimage as ndi\n",
    "import skimage\n",
    "import skimage.measure\n",
    "import skimage.morphology\n",
    "import skimage.segmentation\n",
    "import sklearn.cluster\n",
    "import sklearn.metrics\n",
    "import sklearn.model_selection\n",
    "import sklearn.utils\n",
    "import torch\n",
    "import warnings\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from plotly.graph_objs import *\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, iplot, plot\n",
    "from plotly.tools import FigureFactory as FF\n",
    "from pylab import *\n",
    "from scipy import ndimage\n",
    "from skimage.filters import roberts, sobel\n",
    "from skimage.measure import label, perimeter, regionprops\n",
    "from skimage.morphology import ball, binary_closing, binary_dilation, binary_erosion, binary_opening, closing, dilation, erosion, remove_small_objects, reconstruction\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from medpy.filter.smoothing import anisotropic_diffusion\n",
    "from numpy import asarray, savetxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-y2Es7fe0Ohe",
    "outputId": "28b79bd8-f9d3-49ab-a627-d279f0062793"
   },
   "outputs": [],
   "source": [
    "# check GPU availability\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nn61Y0laG71O",
    "outputId": "92f521f1-5e60-4342-c17b-7b1a894fd313"
   },
   "outputs": [],
   "source": [
    "t = TicToc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_volume(img,desired_depth,desired_width,desired_height):\n",
    "    # Get current depth\n",
    "    current_depth = np.shape(img)[0]\n",
    "    current_width = np.shape(img)[1]\n",
    "    current_height = np.shape(img)[2]\n",
    "    # Compute depth factor\n",
    "    depth = current_depth / desired_depth\n",
    "    width = current_width / desired_width\n",
    "    height = current_height / desired_height\n",
    "    depth_factor = 1 / depth\n",
    "    width_factor = 1 / width\n",
    "    height_factor = 1 / height\n",
    "    # Resize across z-axis\n",
    "    img = ndimage.zoom(img, (depth_factor, width_factor, height_factor), order=1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the scans in given folder path\n",
    "def load_scan(path):\n",
    "    slices = [pydicom.read_file(path + '/' + s) for s in os.listdir(path)]\n",
    "    slices.sort(key = lambda x: int(x.InstanceNumber))\n",
    "        \n",
    "    return slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pixels_hu(scans):\n",
    "    image = np.stack([s.pixel_array for s in scans])\n",
    "    # Convert to int16 (from sometimes int16), \n",
    "    # should be possible as values should always be low enough (<32k)\n",
    "    image = image.astype(np.int16)\n",
    "\n",
    "    # Set outside-of-scan pixels to 0\n",
    "    # The intercept is usually -1024, so air is approximately 0\n",
    "    image[image == -2000] = 0\n",
    "    \n",
    "    # Convert to Hounsfield units (HU)\n",
    "    # Convert to Hounsfield units (HU)\n",
    "    intercept = scans[0].RescaleIntercept if 'RescaleIntercept' in scans[0] else -1024\n",
    "    slope = scans[0].RescaleSlope if 'RescaleSlope' in scans[0] else 1\n",
    "    \n",
    "    if slope != 1:\n",
    "        image = slope * image.astype(np.float64)\n",
    "        image = image.astype(np.int16)\n",
    "        \n",
    "    image += np.int16(intercept)\n",
    "    \n",
    "    return np.array(image, dtype=np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample(image, scan, new_spacing=[1,1,1]):\n",
    "    # Determine current pixel spacing\n",
    "    spacing = map(float, ([scan[0].SliceThickness, scan[0].PixelSpacing[0], scan[0].PixelSpacing[1]]))\n",
    "    spacing = np.array(list(spacing))\n",
    "\n",
    "    resize_factor = spacing / new_spacing\n",
    "    new_real_shape = image.shape * resize_factor\n",
    "    new_shape = np.round(new_real_shape)\n",
    "    real_resize_factor = new_shape / image.shape\n",
    "    new_spacing = spacing / real_resize_factor\n",
    "    \n",
    "    image = ndimage.zoom(image, real_resize_factor)\n",
    "    \n",
    "    return image, new_spacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize the pixel values\n",
    "def make_lungmask(img, display=False):\n",
    "    mean = np.mean(img)\n",
    "    std = np.std(img)\n",
    "    img = img-mean\n",
    "    img = img/std\n",
    "    \n",
    "    middle = img[100:400,100:400] \n",
    "    mean = np.mean(middle)  \n",
    "    max = np.max(img)\n",
    "    min = np.min(img)\n",
    "    #remove the underflow bins\n",
    "    img[img==max]=mean\n",
    "    img[img==min]=mean\n",
    "    \n",
    "    #apply median filter\n",
    "    img= median_filter(img,size=3)\n",
    "    #apply anistropic non-linear diffusion filter- This removes noise without blurring the nodule boundary\n",
    "    img= anisotropic_diffusion(img)\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=2).fit(np.reshape(middle,[np.prod(middle.shape),1]))\n",
    "    centers = sorted(kmeans.cluster_centers_.flatten())\n",
    "    threshold = np.mean(centers)\n",
    "    thresh_img = np.where(img<threshold,1.0,0.0)  # threshold the image\n",
    "    eroded = morphology.erosion(thresh_img,np.ones([4,4]))\n",
    "    dilation = morphology.dilation(eroded,np.ones([10,10]))\n",
    "    labels = measure.label(dilation)\n",
    "    label_vals = np.unique(labels)\n",
    "    regions = measure.regionprops(labels)\n",
    "    good_labels = []\n",
    "    for prop in regions:\n",
    "        B = prop.bbox\n",
    "        if B[2]-B[0]<475 and B[3]-B[1]<475 and B[0]>40 and B[2]<472:\n",
    "            good_labels.append(prop.label)\n",
    "    mask = np.ndarray([512,512],dtype=np.int8)\n",
    "    mask[:] = 0\n",
    "    #\n",
    "    #  The mask here is the mask for the lungs--not the nodes\n",
    "    #  After just the lungs are left, we do another large dilation\n",
    "    #  in order to fill in and out the lung mask \n",
    "    #\n",
    "    for N in good_labels:\n",
    "        mask = mask + np.where(labels==N,1,0)\n",
    "    mask = morphology.dilation(mask,np.ones([10,10])) # one last dilation\n",
    "    # mask consists of 1 and 0. Thus by mutliplying with the orginial image, sections with 1 will remain\n",
    "\n",
    "    if (display):\n",
    "        fig, ax = plt.subplots(3, 2, figsize=[12, 12])\n",
    "        ax[0, 0].set_title(\"Original\")\n",
    "        ax[0, 0].imshow(img, cmap='gray')\n",
    "        ax[0, 0].axis('off')\n",
    "        ax[0, 1].set_title(\"Threshold\")\n",
    "        ax[0, 1].imshow(thresh_img, cmap='gray')\n",
    "        ax[0, 1].axis('off')\n",
    "        ax[1, 0].set_title(\"After Erosion and Dilation\")\n",
    "        ax[1, 0].imshow(dilation, cmap='gray')\n",
    "        ax[1, 0].axis('off')\n",
    "        ax[1, 1].set_title(\"Color Labels\")\n",
    "        ax[1, 1].imshow(labels)\n",
    "        ax[1, 1].axis('off')\n",
    "        ax[2, 0].set_title(\"Final Mask\")\n",
    "        ax[2, 0].imshow(mask, cmap='gray')\n",
    "        ax[2, 0].axis('off')\n",
    "        ax[2, 1].set_title(\"Apply Mask on Original\")\n",
    "        ax[2, 1].imshow(mask*img, cmap='gray')\n",
    "        ax[2, 1].axis('off')\n",
    "        \n",
    "        plt.show()\n",
    "    return mask*img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = glob.glob('Your Path Here//*')\n",
    "folders.sort(key=lambda x: int(x[x.find(\"(\")+1:x.find(\")\")]))\n",
    "mainVol = []\n",
    "\n",
    "for i, path in enumerate(folders):\n",
    "    filepath = os.path.join(path, 'sorted')   \n",
    "    print(filepath)\n",
    "    if os.path.exists(filepath):\n",
    "       \n",
    "        first_patient = load_scan(filepath)\n",
    "        first_patient_pixels = get_pixels_hu(first_patient)\n",
    "        first_patient_pixels = resize_volume(first_patient_pixels,first_patient_pixels.shape[0],512,512)\n",
    "        masked_lung = []\n",
    "        for img in first_patient_pixels:\n",
    "            masked_lung.append(make_lungmask(img, display=False))\n",
    "        \n",
    "        masked_lung = np.array(masked_lung)\n",
    "        #resize \n",
    "        resizedVol = resize_volume(masked_lung,64,128,128)      \n",
    "        mainVol.append(resizedVol) \n",
    "        print(np.shape(mainVol))\n",
    "\n",
    "mainVol = np.array(mainVol)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainVol = np.swapaxes(mainVol,1,3)\n",
    "mainVol = np.swapaxes(mainVol,1,2)\n",
    "print(mainVol.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv file\n",
    "np.save('Your Path Here/normalizeddata.npy', mainVol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainVol = np.load('Your Path Here/normalizeddata.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = torch.from_numpy(data).float()\n",
    "\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        #x = process_scan(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "trainData = MyDataset(mainVol)\n",
    "train_loader = DataLoader(trainData,batch_size=10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, data in enumerate(train_loader):\n",
    "    print('Batch idx {}, data shape {}'.format(batch_idx, data.shape))\n",
    "    plt.imshow(data[0,:,:,30], cmap=plt.cm.bone)  # set the color map to bone\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TFxVJHnrBGha"
   },
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "\n",
    "class UnFlatten(nn.Module):\n",
    "    def forward(self, input, size=131072):\n",
    "        return input.view(input.size(0), 64, 16, 16, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicConv(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size, stride=1, padding=0, dilation=1, groups=1, relu=True,\n",
    "                 bn=True, bias=False):\n",
    "        super(BasicConv, self).__init__()\n",
    "        self.out_channels = out_planes\n",
    "        self.conv = nn.Conv3d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias)\n",
    "\n",
    "        self.bn = nn.BatchNorm3d(out_planes, eps=1e-5, momentum=0.01, affine=True) if bn else None\n",
    "        self.relu = nn.ReLU() if relu else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        # print('conv block output',x.shape)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Autoencoders(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoders, self).__init__()\n",
    "\n",
    "        self.relu = nn.ReLU(True)\n",
    "\n",
    "        ##encoder layers\n",
    "        self.conv_block_1 = BasicConv(1, 16, 3, stride=1, padding=1, bn=True, relu=True)\n",
    "        self.conv_block_2 = BasicConv(16, 32, 3, stride=1, padding=1, bn=True, relu=True)\n",
    "        self.conv_block_3 = BasicConv(32, 64, 3, stride=1, padding=1, bn=True, relu=True)\n",
    "        self.max_pool = nn.MaxPool3d(2)\n",
    "        self.flatten = Flatten()\n",
    "        self.enclinear = nn.Linear(131072, 1024)\n",
    "        ##decoder layers\n",
    "        self.dec_convtrans_1 = nn.ConvTranspose3d(64, 32, 2, stride=2)\n",
    "        self.dec_convtrans_2 = nn.ConvTranspose3d(32, 16, 2, stride=2)\n",
    "        self.dec_convtrans_3 = nn.ConvTranspose3d(16, 1, 2, stride=2)\n",
    "        self.deconv_batch_norm_1 = nn.BatchNorm3d(32)\n",
    "        self.deconv_batch_norm_2 = nn.BatchNorm3d(16)\n",
    "        self.unflatten = UnFlatten()\n",
    "        self.declinear = nn.Linear(1024, 131072)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        code1 = self.conv_block_1(x)\n",
    "        # print(\"code1:\", code1.shape)\n",
    "        code1 = self.max_pool(code1)\n",
    "        # print(\"code1:\", code1.shape)\n",
    "        code2 = self.conv_block_2(code1)\n",
    "        # print(\"code2:\", code2.shape)\n",
    "        code2 = self.max_pool(code2)\n",
    "        # print(\"code2:\", code2.shape)\n",
    "        code3 = self.conv_block_3(code2)\n",
    "        # print(\"code3:\", code3.shape)\n",
    "        code3 = self.max_pool(code3)\n",
    "        #print(\"code3:\", code3.shape)\n",
    "        code3 = self.flatten(code3)\n",
    "        # print(\"code3:\", code3.shape)\n",
    "        code3 = self.enclinear(code3)\n",
    "        # print(\"code3:\", code3.shape)\n",
    "\n",
    "        # Decoder\n",
    "        out1 = self.declinear(code3)\n",
    "        out1 = self.unflatten(out1)\n",
    "        out1 = self.dec_convtrans_1(out1)\n",
    "        # print(\"out1:\", out1.shape)\n",
    "        out1 = self.deconv_batch_norm_1(out1)\n",
    "        # print(\"out1:\", out1.shape)\n",
    "        out2 = self.dec_convtrans_2(out1)\n",
    "        # print(\"out2:\", out2.shape)\n",
    "        out2 = self.deconv_batch_norm_2(out2)\n",
    "        # print(\"out2:\", out2.shape)\n",
    "        out3 = self.dec_convtrans_3(out2)\n",
    "        # print(\"out3:\", out3.shape)\n",
    "\n",
    "        return code3, out3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-_BgGZQ8GiMV",
    "outputId": "dbeac1f2-0f43-4573-d4a6-563a599b8e49"
   },
   "outputs": [],
   "source": [
    "model = Autoencoders()\n",
    "model = model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify loss function\n",
    "criterion = nn.MSELoss()\n",
    "# specify loss function\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001)\n",
    "\n",
    "# number of epochs to train the model\n",
    "n_epochs = 500\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    # monitor training loss\n",
    "    train_loss = 0.0\n",
    "\n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    for data in train_loader:\n",
    "        data = data.unsqueeze(1)\n",
    "        data = data.to(device, dtype=torch.float)\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        encout, outputs = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(outputs, data)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update running training loss\n",
    "        train_loss += loss.item() * data.size(0)\n",
    "\n",
    "    # print avg training statistics\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n",
    "        epoch,\n",
    "        train_loss\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'Your Path Here/Autoencoder.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BOb1VuekpuGz",
    "outputId": "db94a728-4068-45fc-9d3e-54e8ef97b005"
   },
   "outputs": [],
   "source": [
    "enc_output = np.empty((0, 1024), int)\n",
    "for data in train_loader:\n",
    "    data = data.unsqueeze(1)\n",
    "    data = data.to(device=device, dtype=torch.float)\n",
    "    encout, outputs = model(data)\n",
    "    encout = encout.detach().cpu().clone().numpy()\n",
    "    enc_output = np.append(enc_output, encout, axis=0)\n",
    "    print(enc_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enctxt = np.savetxt(\"Your Path Here/enc0.txt\", enc_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_output = np.loadtxt(\"Your Path Here/enc0.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 796
    },
    "id": "FR-4cSFbGzVA",
    "outputId": "d26e2260-b38e-4d64-9a3b-8725f5949406"
   },
   "outputs": [],
   "source": [
    "plt.rcParams['lines.linewidth'] = 20\n",
    "fig = plt.figure(figsize=(100, 60))\n",
    "fig.patch.set_facecolor('slateblue')\n",
    "plt.xlabel(\"Cluster Index\", fontsize=250, color='white')\n",
    "plt.ylabel(\"Euclidean Distances\", fontsize=250, color='white')\n",
    "dend = shc.dendrogram(shc.linkage(enc_output, method='ward'),\n",
    "                      truncate_mode='lastp',  # show only the last p merged clusters\n",
    "                      p=30,  # show only the last p merged clusters\n",
    "                      leaf_rotation=90.,\n",
    "                      leaf_font_size=12.,\n",
    "                      show_contracted=True,\n",
    "                      # color_threshold=5500,\n",
    "                      )\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis='x', which='major', labelsize=150, colors='white')\n",
    "ax.tick_params(axis='y', which='major', labelsize=150, colors='white')\n",
    "\n",
    "# Add a horizontal line for 2 clusters\n",
    "ax.axhline(y=2750, linestyle='--', color='red', linewidth=15)\n",
    "\n",
    "# Get the x-positions of the vertical lines\n",
    "x_vals = dend['icoord']\n",
    "\n",
    "# Iterate over the x-positions and find the intersection points with the horizontal line\n",
    "for i, x in enumerate(x_vals):\n",
    "    for j in range(len(x)):\n",
    "        y = dend['dcoord'][i][j]\n",
    "        if abs(y - 2750) < 1e-5:  # check if the y-coordinate is close to the horizontal line\n",
    "            ax.annotate('', xy=(x[j], y), xytext=(x[j], y + 20), arrowprops=dict(facecolor='white', edgecolor='white', arrowstyle='-|>,head_width=1,head_length=3'), fontsize=150)\n",
    "\n",
    "plt.savefig('Your Path Here/HC.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4MFEAbx6pR44",
    "outputId": "95260291-1837-4dff-dfb1-149016bc79f8"
   },
   "outputs": [],
   "source": [
    "avg_dist = []\n",
    "for c in range(1,11):\n",
    "  cluster = AgglomerativeClustering(n_clusters=c, affinity='euclidean', linkage='ward')\n",
    "  members = cluster.fit_predict(enc_output)\n",
    "  k = np.unique(members)\n",
    "  num_clusters = k.shape[0]\n",
    "  sum = 0\n",
    "  for cluster in range(num_clusters):\n",
    "    cluster_sum = 0  \n",
    "    cluster_sum = pairwise_distances(enc_output[members == cluster]).mean()  \n",
    "    sum += cluster_sum\n",
    "  sum = sum/num_clusters\n",
    "  avg_dist.append(sum)\n",
    "\n",
    "print(avg_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_txt = np.savetxt(\"Your Path Here/avg_dist0.txt\", avg_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_dist = np.loadtxt('Your Path Here/avg_dist0.txt')\n",
    "avg_dist = avg_dist.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "NFMtXO_CrP3p",
    "outputId": "6c62b872-2f96-4a5d-e692-cac8a7038639"
   },
   "outputs": [],
   "source": [
    "plt.rcParams['lines.linewidth'] = 30\n",
    "fig = plt.figure(figsize=(100, 60))\n",
    "fig.patch.set_facecolor('slateblue')\n",
    "plt.xlabel(\"Number of Phenotypes\", fontsize=250, color='white')\n",
    "plt.ylabel(\"Intra-cluster Distance\", fontsize=250, color='white')\n",
    "plt.plot(range(1,11), avg_dist, color='mediumvioletred')\n",
    "plt.xticks(range(1, 11))\n",
    "ax = plt.gca()\n",
    "ax.set_facecolor('midnightblue')\n",
    "ax.tick_params(axis='x', labelsize=200, colors='white')\n",
    "ax.tick_params(axis='y', labelsize=200, colors='white')\n",
    "#vlines(x=14, ymin=bottom, ymax=avg_dist[15], linewidth=4, color='r')\n",
    "plt.savefig('Your Path Here/elbow0.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = []\n",
    "for i in range(0,10):    \n",
    "    test = (avg_dist[i-1] - avg_dist[i]) / avg_dist[i-1]\n",
    "    test1.append(test)\n",
    "\n",
    "max_value = max(test1)\n",
    "index = test1.index(max_value)\n",
    "print(index+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o2MQTmBtujOl"
   },
   "outputs": [],
   "source": [
    "cluster = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='ward')\n",
    "members = cluster.fit_predict(enc_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F4ic-UNYrRMm",
    "outputId": "4f8a227b-fabd-4c84-9332-61dbec352133"
   },
   "outputs": [],
   "source": [
    "labels = members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelstxt = np.savetxt(\"Your Path Here/labels.txt\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.loadtxt(\"Your Path Here/labels.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = torch.from_numpy(data).float()\n",
    "        self.labels = labels.long()\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.labels[index]\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "labels = torch.from_numpy(labels)\n",
    "trainData = MyDataset(mainVol, labels)\n",
    "train_loader = DataLoader(trainData,batch_size=10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "    \n",
    "class ClassificationModel(nn.Module):   \n",
    "    def __init__(self):\n",
    "        super(ClassificationModel, self).__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            # Defining a 3D convolution layer\n",
    "            nn.Conv3d(1,64,3, stride=1, padding=1),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d((2,2,2)),\n",
    "            # Defining another 3D convolution layer\n",
    "            nn.Conv3d(64,32,3, stride=1, padding=1),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d((2,2,2)),\n",
    "            # Defining another 3D convolution layer\n",
    "            nn.Conv3d(32,16,3, stride=1, padding=1),\n",
    "            nn.BatchNorm3d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d((2,2,2))\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            Flatten(),\n",
    "            nn.Linear(32768, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            #nn.Dropout3d(p=0.5),\n",
    "            nn.Linear(256, 3)\n",
    "        )\n",
    "\n",
    "    # Defining the forward pass    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ClassificationModel()\n",
    "model = model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.tic()\n",
    "#specify loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# specify loss function\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001)\n",
    "\n",
    "# number of epochs to train the model\n",
    "n_epochs = 50\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    # monitor training loss\n",
    "    train_loss = 0.0\n",
    "\n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    for data, labels in train_loader:\n",
    "        data = data.unsqueeze(1)\n",
    "        data = data.to(device, dtype=torch.float)\n",
    "        labels = labels.to(device=device)\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        outputs = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update running training loss\n",
    "        train_loss += loss.item() * data.size(0)\n",
    "\n",
    "    # print avg training statistics\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n",
    "        epoch,\n",
    "        train_loss\n",
    "    ))\n",
    "\n",
    "timeTaken = t.tocvalue()/60\n",
    "dispMsg = \"++++ Total Time Taken: %.2f\" % timeTaken\n",
    "print( dispMsg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'Your Path Here/Classifier.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradCAMModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GradCAMModel, self).__init__()\n",
    "        \n",
    "        # get the classification network\n",
    "        self.gradcam = model\n",
    "        \n",
    "        # disect the network to access its last convolutional layer\n",
    "        self.features_conv = self.gradcam.features[:11]\n",
    "        \n",
    "        # get the max pool of the features stem\n",
    "        self.max_pool = nn.MaxPool3d((2,2,2))\n",
    "        \n",
    "        # get the classifier of the model\n",
    "        self.classifier = self.gradcam.classifier\n",
    "        \n",
    "        # placeholder for the gradients\n",
    "        self.gradients = None\n",
    "    \n",
    "    # hook for the gradients of the activations\n",
    "    def activations_hook(self, grad):\n",
    "        self.gradients = grad\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features_conv(x)\n",
    "        \n",
    "        # register the hook\n",
    "        h = x.register_hook(self.activations_hook)\n",
    "        \n",
    "        # apply the remaining pooling\n",
    "        x = self.max_pool(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "    # method for the gradient extraction\n",
    "    def get_activations_gradient(self):\n",
    "        return self.gradients\n",
    "    \n",
    "    # method for the activation exctraction\n",
    "    def get_activations(self, x):\n",
    "        return self.features_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = GradCAMModel()\n",
    "model2 = model2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model2, 'Your Path Here/GradCAM.pth')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CBAM_Ver2_NormRevised.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
